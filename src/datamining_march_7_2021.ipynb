{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uber Pick-up Demand Prediction using LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPSC8650 Data Mining\n",
    "### Spring 2021, Clemson University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nirali Bandaru, Rohan Gangisetty, Rajesh Kandimalla "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing data sets as dataframes using Pandas\n",
    "apr_df = pd.read_csv(r\"C:\\Users\\niral\\OneDrive\\Documents\\Clemson\\Semester 4\\Data Mining\\Project\\Uber\\Data\\modified data2\\uber-raw-data-apr14.csv\")\n",
    "may_df = pd.read_csv(r\"C:\\Users\\niral\\OneDrive\\Documents\\Clemson\\Semester 4\\Data Mining\\Project\\Uber\\Data\\modified data2\\uber-raw-data-may14.csv\")\n",
    "jun_df = pd.read_csv(r\"C:\\Users\\niral\\OneDrive\\Documents\\Clemson\\Semester 4\\Data Mining\\Project\\Uber\\Data\\modified data2\\uber-raw-data-jun14.csv\")\n",
    "jul_df = pd.read_csv(r\"C:\\Users\\niral\\OneDrive\\Documents\\Clemson\\Semester 4\\Data Mining\\Project\\Uber\\Data\\modified data2\\uber-raw-data-jul14.csv\")\n",
    "aug_df = pd.read_csv(r\"C:\\Users\\niral\\OneDrive\\Documents\\Clemson\\Semester 4\\Data Mining\\Project\\Uber\\Data\\modified data2\\uber-raw-data-aug14.csv\")\n",
    "sep_df = pd.read_csv(r\"C:\\Users\\niral\\OneDrive\\Documents\\Clemson\\Semester 4\\Data Mining\\Project\\Uber\\Data\\modified data2\\uber-raw-data-sep14.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "April: \n",
      "        Date     Time      Lat      Lon    Base\n",
      "0  4/1/2014  0:11:00  40.7690 -73.9549  B02512\n",
      "1  4/1/2014  0:17:00  40.7267 -74.0345  B02512\n",
      "2  4/1/2014  0:21:00  40.7316 -73.9873  B02512\n",
      "3  4/1/2014  0:28:00  40.7588 -73.9776  B02512\n",
      "4  4/1/2014  0:33:00  40.7594 -73.9722  B02512\n",
      "Number of rows:  Date    564516\n",
      "Time    564516\n",
      "Lat     564516\n",
      "Lon     564516\n",
      "Base    564516\n",
      "dtype: int64\n",
      "Null values:  Date    0\n",
      "Time    0\n",
      "Lat     0\n",
      "Lon     0\n",
      "Base    0\n",
      "dtype: int64\n",
      "May: \n",
      "        Date     Time      Lat      Lon    Base\n",
      "0  5/1/2014  0:02:00  40.7521 -73.9914  B02512\n",
      "1  5/1/2014  0:06:00  40.6965 -73.9715  B02512\n",
      "2  5/1/2014  0:15:00  40.7464 -73.9838  B02512\n",
      "3  5/1/2014  0:17:00  40.7463 -74.0011  B02512\n",
      "4  5/1/2014  0:17:00  40.7594 -73.9734  B02512\n",
      "Number of rows:  Date    652435\n",
      "Time    652434\n",
      "Lat     652435\n",
      "Lon     652435\n",
      "Base    652435\n",
      "dtype: int64\n",
      "Null values:  Date    0\n",
      "Time    1\n",
      "Lat     0\n",
      "Lon     0\n",
      "Base    0\n",
      "dtype: int64\n",
      "Jun: \n",
      "        Date     Time      Lat      Lon    Base\n",
      "0  6/1/2014  0:00:00  40.7293 -73.9920  B02512\n",
      "1  6/1/2014  0:01:00  40.7131 -74.0097  B02512\n",
      "2  6/1/2014  0:04:00  40.3461 -74.6610  B02512\n",
      "3  6/1/2014  0:04:00  40.7555 -73.9833  B02512\n",
      "4  6/1/2014  0:07:00  40.6880 -74.1831  B02512\n",
      "Number of rows:  Date    663844\n",
      "Time    663844\n",
      "Lat     663844\n",
      "Lon     663844\n",
      "Base    663844\n",
      "dtype: int64\n",
      "Null values:  Date    0\n",
      "Time    0\n",
      "Lat     0\n",
      "Lon     0\n",
      "Base    0\n",
      "dtype: int64\n",
      "Jul: \n",
      "        Date     Time      Lat      Lon    Base\n",
      "0  7/1/2014  0:03:00  40.7586 -73.9706  B02512\n",
      "1  7/1/2014  0:05:00  40.7605 -73.9994  B02512\n",
      "2  7/1/2014  0:06:00  40.7320 -73.9999  B02512\n",
      "3  7/1/2014  0:09:00  40.7635 -73.9793  B02512\n",
      "4  7/1/2014  0:20:00  40.7204 -74.0047  B02512\n",
      "Number of rows:  Date    796121\n",
      "Time    796121\n",
      "Lat     796121\n",
      "Lon     796121\n",
      "Base    796121\n",
      "dtype: int64\n",
      "Null values:  Date    0\n",
      "Time    0\n",
      "Lat     0\n",
      "Lon     0\n",
      "Base    0\n",
      "dtype: int64\n",
      "Aug: \n",
      "        Date     Time      Lat      Lon    Base\n",
      "0  8/1/2014  0:03:00  40.7366 -73.9906  B02512\n",
      "1  8/1/2014  0:09:00  40.7260 -73.9918  B02512\n",
      "2  8/1/2014  0:12:00  40.7209 -74.0507  B02512\n",
      "3  8/1/2014  0:12:00  40.7387 -73.9856  B02512\n",
      "4  8/1/2014  0:12:00  40.7323 -74.0077  B02512\n",
      "Number of rows:  Date    829275\n",
      "Time    829273\n",
      "Lat     829275\n",
      "Lon     829275\n",
      "Base    829275\n",
      "dtype: int64\n",
      "Null values:  Date    0\n",
      "Time    2\n",
      "Lat     0\n",
      "Lon     0\n",
      "Base    0\n",
      "dtype: int64\n",
      "Sep: \n",
      "        Date     Time      Lat      Lon    Base\n",
      "0  9/1/2014  0:01:00  40.2201 -74.0021  B02512\n",
      "1  9/1/2014  0:01:00  40.7500 -74.0027  B02512\n",
      "2  9/1/2014  0:03:00  40.7559 -73.9864  B02512\n",
      "3  9/1/2014  0:06:00  40.7450 -73.9889  B02512\n",
      "4  9/1/2014  0:11:00  40.8145 -73.9444  B02512\n",
      "Number of rows:  Date    1028136\n",
      "Time    1028136\n",
      "Lat     1028136\n",
      "Lon     1028136\n",
      "Base    1028136\n",
      "dtype: int64\n",
      "Null values:  Date    0\n",
      "Time    0\n",
      "Lat     0\n",
      "Lon     0\n",
      "Base    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#EXPLORING and VIEWING THE IMPORTED DATAFRAMES\n",
    "\n",
    "#APRIL\n",
    "print(\"April: \\n\", apr_df.head())\n",
    "print(\"Number of rows: \", apr_df.count())\n",
    "print(\"Null values: \", apr_df.isnull().sum())\n",
    "\n",
    "#MAY\n",
    "print(\"May: \\n\", may_df.head())\n",
    "print(\"Number of rows: \", may_df.count())\n",
    "print(\"Null values: \", may_df.isnull().sum())\n",
    "\n",
    "#JUN\n",
    "print(\"Jun: \\n\", jun_df.head())\n",
    "print(\"Number of rows: \", jun_df.count())\n",
    "print(\"Null values: \", jun_df.isnull().sum())\n",
    "\n",
    "#JUL\n",
    "print(\"Jul: \\n\", jul_df.head())\n",
    "print(\"Number of rows: \", jul_df.count())\n",
    "print(\"Null values: \", jul_df.isnull().sum())\n",
    "\n",
    "#AUG\n",
    "print(\"Aug: \\n\", aug_df.head())\n",
    "print(\"Number of rows: \", aug_df.count())\n",
    "print(\"Null values: \", aug_df.isnull().sum())\n",
    "\n",
    "#SEP\n",
    "print(\"Sep: \\n\", sep_df.head())\n",
    "print(\"Number of rows: \", sep_df.count())\n",
    "print(\"Null values: \", sep_df.isnull().sum())\n",
    "\n",
    "total_number_of_rows = 4534327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list of all dataframes to combine\n",
    "df_list = [apr_df, may_df, jun_df, jul_df, aug_df, sep_df]\n",
    "\n",
    "#Concatenate dataframes with pandas\n",
    "dataframe = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date    4534327\n",
       "Time    4534324\n",
       "Lat     4534327\n",
       "Lon     4534327\n",
       "Base    4534327\n",
       "dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verify number of rows and format with count() and head(), respectively\n",
    "dataframe.head()\n",
    "dataframe.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-35943242c66e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Write new dataframe as combined csv file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"combined_new.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \"\"\"\n\u001b[0;32m      5\u001b[0m \u001b[0mNOTE\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThere\u001b[0m \u001b[0mare\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0mof\u001b[0m \u001b[1;36m4534327\u001b[0m \u001b[0mrows\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcombined\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mexcel\u001b[0m \u001b[0mcan\u001b[0m \u001b[0monly\u001b[0m \u001b[0mdisplay\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmaximum\u001b[0m \u001b[0mof\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[0;32m   3168\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3169\u001b[0m         )\n\u001b[1;32m-> 3170\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m             )\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    360\u001b[0m         )\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[0mlibwriters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_csv_rows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mpandas\\_libs\\writers.pyx\u001b[0m in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied"
     ]
    }
   ],
   "source": [
    "#Write new dataframe as combined csv file\n",
    "dataframe.to_csv(\"combined_new.csv\")\n",
    "\n",
    "\"\"\"\n",
    "NOTE: There are a total of 4534327 rows in the combined dataframe, and excel can only display a maximum of\n",
    "1,048,576 rows. To view all data, open file in Notepad++\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for missing values\n",
    "\n",
    "dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing missing values\n",
    "\n",
    "null_data = dataframe[dataframe.isnull().any(axis=1)]\n",
    "print(null_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify that there are no missing values\n",
    "\n",
    "count_of_null_values_total = dataframe.isnull().values.sum()\n",
    "count_of_null_values_for_each_column = dataframe.isnull().sum()\n",
    "boolean_result_for_null_values = dataframe.isnull().values.any()\n",
    "\n",
    "print(\"Total null values: \", count_of_null_values_total)\n",
    "print(\"Count of null values for each column: \", count_of_null_values_for_each_column)\n",
    "print(\"Do null values exist? \", boolean_result_for_null_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing dtype object to appropriate data types for each column\n",
    "\n",
    "dataframe['Date'] = pd.to_datetime(dataframe['Date'], errors = \"coerce\")\n",
    "dataframe['Time'] = pd.to_datetime(dataframe['Time'], errors = \"coerce\")\n",
    "dataframe['Time'] = [time.time() for time in dataframe['Time']]\n",
    "dataframe['Lat'] = pd.to_numeric(dataframe['Lat'], errors = \"coerce\")\n",
    "dataframe['Lon'] = pd.to_numeric(dataframe['Lon'], errors = \"coerce\")\n",
    "dataframe['Base'] = dataframe['Base'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking mininum and maximum values for each attribute\n",
    "print(\"ATTRIBUTE RANGES\\n\")\n",
    "print(\"DATE    Min: \", dataframe[\"Date\"].min(), \"Max: \", dataframe[\"Date\"].max())\n",
    "print(\"TIME    Min: \", dataframe[\"Time\"].min(), \"Max: \", dataframe[\"Time\"].max())\n",
    "print(\"LAT     Min: \", dataframe[\"Lat\"].min(), \"Max: \", dataframe[\"Lat\"].max())\n",
    "print(\"LON     Min: \", dataframe[\"Lon\"].min(), \"Max: \", dataframe[\"Lon\"].max())\n",
    "print(\"BASE    Min: \", dataframe[\"Base\"].min(), \"Max: \", dataframe[\"Base\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
